---
- url: "github:mudler/LocalAI/gallery/moondream.yaml@master"
  license: apache-2.0
  icon: https://cdn-avatars.huggingface.co/v1/production/uploads/65df6605dba41b152100edf9/LEUWPRTize9N7dMShjcPC.png
  description: |
    Moondream is a small vision language model designed to run efficiently everywhere.
  urls:
    - https://huggingface.co/vikhyatk/moondream2
    - https://huggingface.co/ggml-org/moondream2-20250414-GGUF
  tags:
    - llm
    - multimodal
    - gguf
    - moondream
    - gpu
    - image-to-text
    - vision
    - cpu
  name: "moondream2-20250414"
  overrides:
    mmproj: moondream2-mmproj-f16-20250414.gguf
    parameters:
      model: moondream2-text-model-f16.gguf
  files:
    - filename: moondream2-mmproj-f16-20250414.gguf
      sha256: 4cc1cb3660d87ff56432ebeb7884ad35d67c48c7b9f6b2856f305e39c38eed8f
      uri: https://www.modelscope.cn/models/ggml-org/moondream2-20250414-GGUF/resolve/master/moondream2-mmproj-f16-20250414.gguf
- &smolvlm
  url: "github:mudler/LocalAI/gallery/smolvlm.yaml@master"
  name: "smolvlm-256m-instruct"
  icon: https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/SmolVLM_256_banner.png
  urls:
    - https://huggingface.co/HuggingFaceTB/SmolVLM-256M-Instruct
    - https://huggingface.co/ggml-org/SmolVLM-256M-Instruct-GGUF
  license: apache-2.0
  description: |
    SmolVLM-256M is the smallest multimodal model in the world. It accepts arbitrary sequences of image and text inputs to produce text outputs. It's designed for efficiency. SmolVLM can answer questions about images, describe visual content, or transcribe text. Its lightweight architecture makes it suitable for on-device applications while maintaining strong performance on multimodal tasks. It can run inference on one image with under 1GB of GPU RAM.
  tags:
    - llm
    - gguf
    - gpu
    - cpu
    - vision
    - multimodal
    - smollvlm
    - image-to-text
  overrides:
    parameters:
      model: SmolVLM-256M-Instruct-Q8_0.gguf
    mmproj: mmproj-SmolVLM-256M-Instruct-Q8_0.gguf
  files:
    - filename: mmproj-SmolVLM-256M-Instruct-Q8_0.gguf
      sha256: 7e943f7c53f0382a6fc41b6ee0c2def63ba4fded9ab8ed039cc9e2ab905e0edd
      uri: huggingface://ggml-org/SmolVLM-256M-Instruct-GGUF/mmproj-SmolVLM-256M-Instruct-Q8_0.gguf
    - filename: SmolVLM-256M-Instruct-Q8_0.gguf
      sha256: 2a31195d3769c0b0fd0a4906201666108834848db768af11de1d2cef7cd35e65
      uri: huggingface://ggml-org/SmolVLM-256M-Instruct-GGUF/SmolVLM-256M-Instruct-Q8_0.gguf
- !!merge <<: *smolvlm
  name: "smolvlm-500m-instruct"
  urls:
    - https://huggingface.co/HuggingFaceTB/SmolVLM-500M-Instruct
    - https://huggingface.co/ggml-org/SmolVLM-500M-Instruct-GGUF
  description: |
    SmolVLM-500M is a tiny multimodal model, member of the SmolVLM family. It accepts arbitrary sequences of image and text inputs to produce text outputs. It's designed for efficiency. SmolVLM can answer questions about images, describe visual content, or transcribe text. Its lightweight architecture makes it suitable for on-device applications while maintaining strong performance on multimodal tasks. It can run inference on one image with 1.23GB of GPU RAM.
  overrides:
    parameters:
      model: SmolVLM-500M-Instruct-Q8_0.gguf
    mmproj: mmproj-SmolVLM-500M-Instruct-Q8_0.gguf
  files:
    - filename: mmproj-SmolVLM-500M-Instruct-Q8_0.gguf
      sha256: d1eb8b6b23979205fdf63703ed10f788131a3f812c7b1f72e0119d5d81295150
      uri: huggingface://ggml-org/SmolVLM-500M-Instruct-GGUF/mmproj-SmolVLM-500M-Instruct-Q8_0.gguf
    - filename: SmolVLM-500M-Instruct-Q8_0.gguf
      sha256: 9d4612de6a42214499e301494a3ecc2be0abdd9de44e663bda63f1152fad1bf4
      uri: huggingface://ggml-org/SmolVLM-500M-Instruct-GGUF/SmolVLM-500M-Instruct-Q8_0.gguf
- !!merge <<: *smolvlm
  name: "smolvlm-instruct"
  icon: https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/SmolVLM.png
  urls:
    - https://huggingface.co/HuggingFaceTB/SmolVLM-Instruct
    - https://huggingface.co/ggml-org/SmolVLM-Instruct-GGUF
  description: |
    SmolVLM is a compact open multimodal model that accepts arbitrary sequences of image and text inputs to produce text outputs. Designed for efficiency, SmolVLM can answer questions about images, describe visual content, create stories grounded on multiple images, or function as a pure language model without visual inputs. Its lightweight architecture makes it suitable for on-device applications while maintaining strong performance on multimodal tasks.
  overrides:
    parameters:
      model: SmolVLM-Instruct-Q4_K_M.gguf
    mmproj: mmproj-SmolVLM-Instruct-Q8_0.gguf
  files:
    - filename: SmolVLM-Instruct-Q4_K_M.gguf
      sha256: dc80966bd84789de64115f07888939c03abb1714d431c477dfb405517a554af5
      uri: https://huggingface.co/ggml-org/SmolVLM-Instruct-GGUF/resolve/main/SmolVLM-Instruct-Q4_K_M.gguf
    - filename: mmproj-SmolVLM-Instruct-Q8_0.gguf
      sha256: 86b84aa7babf1ab51a6366d973b9d380354e92c105afaa4f172cc76d044da739
      uri: https://huggingface.co/ggml-org/SmolVLM-Instruct-GGUF/resolve/main/mmproj-SmolVLM-Instruct-Q8_0.gguf
- !!merge <<: *smolvlm
  name: "smolvlm2-2.2b-instruct"
  icon: https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/SmolVLM2_banner.png
  urls:
    - https://huggingface.co/HuggingFaceTB/SmolVLM2-2.2B-Instruct
    - https://huggingface.co/ggml-org/SmolVLM2-2.2B-Instruct-GGUF
  description: |
    SmolVLM2-2.2B is a lightweight multimodal model designed to analyze video content. The model processes videos, images, and text inputs to generate text outputs - whether answering questions about media files, comparing visual content, or transcribing text from images. Despite its compact size, requiring only 5.2GB of GPU RAM for video inference, it delivers robust performance on complex multimodal tasks. This efficiency makes it particularly well-suited for on-device applications where computational resources may be limited.
  overrides:
    parameters:
      model: SmolVLM2-2.2B-Instruct-Q4_K_M.gguf
    mmproj: mmproj-SmolVLM2-2.2B-Instruct-Q8_0.gguf
  files:
    - filename: SmolVLM2-2.2B-Instruct-Q4_K_M.gguf
      sha256: 0cf76814555b8665149075b74ab6b5c1d428ea1d3d01c1918c12012e8d7c9f58
      uri: huggingface://ggml-org/SmolVLM2-2.2B-Instruct-GGUF/SmolVLM2-2.2B-Instruct-Q4_K_M.gguf
    - filename: mmproj-SmolVLM2-2.2B-Instruct-Q8_0.gguf
      sha256: ae07ea1facd07dd3230c4483b63e8cda96c6944ad2481f33d531f79e892dd024
      uri: huggingface://ggml-org/SmolVLM2-2.2B-Instruct-GGUF/mmproj-SmolVLM2-2.2B-Instruct-Q8_0.gguf
- !!merge <<: *smolvlm
  name: "smolvlm2-500m-video-instruct"
  icon: https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/SmolVLM2_banner.png
  urls:
    - https://huggingface.co/HuggingFaceTB/SmolVLM2-500M-Video-Instruct
    - https://huggingface.co/ggml-org/SmolVLM2-500M-Video-Instruct-GGUF
  description: |
    SmolVLM2-500M-Video is a lightweight multimodal model designed to analyze video content.
    The model processes videos, images, and text inputs to generate text outputs - whether answering questions about media files, comparing visual content, or transcribing text from images. Despite its compact size, requiring only 1.8GB of GPU RAM for video inference, it delivers robust performance on complex multimodal tasks.
    This efficiency makes it particularly well-suited for on-device applications where computational resources may be limited.
  overrides:
    parameters:
      model: SmolVLM2-500M-Video-Instruct-f16.gguf
    mmproj: mmproj-SmolVLM2-500M-Video-Instruct-f16.gguf
  files:
    - filename: SmolVLM2-500M-Video-Instruct-f16.gguf
      sha256: 80f7e3f04bc2d3324ac1a9f52f5776fe13a69912adf74f8e7edacf773d140d77
      uri: huggingface://ggml-org/SmolVLM2-500M-Video-Instruct-GGUF/SmolVLM2-500M-Video-Instruct-f16.gguf
    - filename: mmproj-SmolVLM2-500M-Video-Instruct-f16.gguf
      sha256: b5dc8ebe7cbeab66a5369693960a52515d7824f13d4063ceca78431f2a6b59b0
      uri: huggingface://ggml-org/SmolVLM2-500M-Video-Instruct-GGUF/mmproj-SmolVLM2-500M-Video-Instruct-f16.gguf
- !!merge <<: *smolvlm
  name: "smolvlm2-256m-video-instruct"
  icon: https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/SmolVLM2_banner.png
  urls:
    - https://huggingface.co/HuggingFaceTB/SmolVLM2-256M-Video-Instruct
    - https://huggingface.co/ggml-org/SmolVLM2-256M-Video-Instruct-GGUF
  description: |
    SmolVLM2-256M-Video is a lightweight multimodal model designed to analyze video content. The model processes videos, images, and text inputs to generate text outputs - whether answering questions about media files, comparing visual content, or transcribing text from images. Despite its compact size, requiring only 1.38GB of GPU RAM for video inference. This efficiency makes it particularly well-suited for on-device applications that require specific domain fine-tuning and computational resources may be limited.
  overrides:
    parameters:
      model: SmolVLM2-256M-Video-Instruct-Q8_0.gguf
    mmproj: mmproj-SmolVLM2-256M-Video-Instruct-Q8_0.gguf
  files:
    - filename: SmolVLM2-256M-Video-Instruct-Q8_0.gguf
      sha256: af7ce9951a2f46c4f6e5def253e5b896ca5e417010e7a9949fdc9e5175c27767
      uri: huggingface://ggml-org/SmolVLM2-256M-Video-Instruct-GGUF/SmolVLM2-256M-Video-Instruct-Q8_0.gguf
    - filename: mmproj-SmolVLM2-256M-Video-Instruct-Q8_0.gguf
      sha256: d34913a588464ff7215f086193e0426a4f045eaba74456ee5e2667d8ed6798b1
      uri: huggingface://ggml-org/SmolVLM2-256M-Video-Instruct-GGUF/mmproj-SmolVLM2-256M-Video-Instruct-Q8_0.gguf
- &qwen3
  url: "github:mudler/LocalAI/gallery/qwen3.yaml@master"
  name: "qwen3-30b-a3b"
  urls:
    - https://huggingface.co/Qwen/Qwen3-30B-A3B
    - https://huggingface.co/bartowski/Qwen_Qwen3-30B-A3B-GGUF
  icon: https://cdn-avatars.huggingface.co/v1/production/uploads/620760a26e3b7210c2ff1943/-s1gyJfvbE1RgO5iBeNOi.png
  license: apache-2.0
  description: |
    Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Built upon extensive training, Qwen3 delivers groundbreaking advancements in reasoning, instruction-following, agent capabilities, and multilingual support, with the following key features:

      Uniquely support of seamless switching between thinking mode (for complex logical reasoning, math, and coding) and non-thinking mode (for efficient, general-purpose dialogue) within single model, ensuring optimal performance across various scenarios.
      Significantly enhancement in its reasoning capabilities, surpassing previous QwQ (in thinking mode) and Qwen2.5 instruct models (in non-thinking mode) on mathematics, code generation, and commonsense logical reasoning.
      Superior human preference alignment, excelling in creative writing, role-playing, multi-turn dialogues, and instruction following, to deliver a more natural, engaging, and immersive conversational experience.
      Expertise in agent capabilities, enabling precise integration with external tools in both thinking and unthinking modes and achieving leading performance among open-source models in complex agent-based tasks.
      Support of 100+ languages and dialects with strong capabilities for multilingual instruction following and translation.
    Qwen3-30B-A3B has the following features:

        Type: Causal Language Models
        Training Stage: Pretraining & Post-training
        Number of Parameters: 30.5B in total and 3.3B activated
        Number of Paramaters (Non-Embedding): 29.9B
        Number of Layers: 48
        Number of Attention Heads (GQA): 32 for Q and 4 for KV
        Number of Experts: 128
        Number of Activated Experts: 8
        Context Length: 32,768 natively and 131,072 tokens with YaRN.

    For more details, including benchmark evaluation, hardware requirements, and inference performance, please refer to our blog, GitHub, and Documentation.
  tags:
    - llm
    - gguf
    - gpu
    - cpu
    - qwen
    - qwen3
    - thinking
    - reasoning
  overrides:
    parameters:
      model: Qwen_Qwen3-30B-A3B-Q4_K_M.gguf
  files:
    - filename: Qwen_Qwen3-30B-A3B-Q4_K_M.gguf
      sha256: a015794bfb1d69cb03dbb86b185fb2b9b339f757df5f8f9dd9ebdab8f6ed5d32
      uri: huggingface://bartowski/Qwen_Qwen3-30B-A3B-GGUF/Qwen_Qwen3-30B-A3B-Q4_K_M.gguf
- !!merge <<: *qwen3
  name: "qwen3-32b"
  urls:
    - https://huggingface.co/Qwen/Qwen3-32B
    - https://huggingface.co/bartowski/Qwen_Qwen3-32B-GGUF
  description: |
    Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Built upon extensive training, Qwen3 delivers groundbreaking advancements in reasoning, instruction-following, agent capabilities, and multilingual support, with the following key features:

        Uniquely support of seamless switching between thinking mode (for complex logical reasoning, math, and coding) and non-thinking mode (for efficient, general-purpose dialogue) within single model, ensuring optimal performance across various scenarios.
        Significantly enhancement in its reasoning capabilities, surpassing previous QwQ (in thinking mode) and Qwen2.5 instruct models (in non-thinking mode) on mathematics, code generation, and commonsense logical reasoning.
        Superior human preference alignment, excelling in creative writing, role-playing, multi-turn dialogues, and instruction following, to deliver a more natural, engaging, and immersive conversational experience.
        Expertise in agent capabilities, enabling precise integration with external tools in both thinking and unthinking modes and achieving leading performance among open-source models in complex agent-based tasks.
        Support of 100+ languages and dialects with strong capabilities for multilingual instruction following and translation.

    Qwen3-32B has the following features:

        Type: Causal Language Models
        Training Stage: Pretraining & Post-training
        Number of Parameters: 32.8B
        Number of Paramaters (Non-Embedding): 31.2B
        Number of Layers: 64
        Number of Attention Heads (GQA): 64 for Q and 8 for KV
        Context Length: 32,768 natively and 131,072 tokens with YaRN.

        For more details, including benchmark evaluation, hardware requirements, and inference performance, please refer to our blog, GitHub, and Documentation.
  overrides:
    parameters:
      model: Qwen_Qwen3-32B-Q4_K_M.gguf
  files:
    - filename: Qwen_Qwen3-32B-Q4_K_M.gguf
      sha256: e41ec56ddd376963a116da97506fadfccb50fb402bb6f3cb4be0bc179a582bd6
      uri: huggingface://bartowski/Qwen_Qwen3-32B-GGUF/Qwen_Qwen3-32B-Q4_K_M.gguf
- !!merge <<: *qwen3
  name: "qwen3-14b"
  urls:
    - https://huggingface.co/Qwen/Qwen3-14B
    - https://huggingface.co/MaziyarPanahi/Qwen3-14B-GGUF
  description: |
    Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Built upon extensive training, Qwen3 delivers groundbreaking advancements in reasoning, instruction-following, agent capabilities, and multilingual support, with the following key features:

        Uniquely support of seamless switching between thinking mode (for complex logical reasoning, math, and coding) and non-thinking mode (for efficient, general-purpose dialogue) within single model, ensuring optimal performance across various scenarios.
        Significantly enhancement in its reasoning capabilities, surpassing previous QwQ (in thinking mode) and Qwen2.5 instruct models (in non-thinking mode) on mathematics, code generation, and commonsense logical reasoning.
        Superior human preference alignment, excelling in creative writing, role-playing, multi-turn dialogues, and instruction following, to deliver a more natural, engaging, and immersive conversational experience.
        Expertise in agent capabilities, enabling precise integration with external tools in both thinking and unthinking modes and achieving leading performance among open-source models in complex agent-based tasks.
        Support of 100+ languages and dialects with strong capabilities for multilingual instruction following and translation.

    Qwen3-14B has the following features:

        Type: Causal Language Models
        Training Stage: Pretraining & Post-training
        Number of Parameters: 14.8B
        Number of Paramaters (Non-Embedding): 13.2B
        Number of Layers: 40
        Number of Attention Heads (GQA): 40 for Q and 8 for KV
        Context Length: 32,768 natively and 131,072 tokens with YaRN.

    For more details, including benchmark evaluation, hardware requirements, and inference performance, please refer to our blog, GitHub, and Documentation.
  overrides:
    parameters:
      model: Qwen3-14B.Q4_K_M.gguf
  files:
    - filename: Qwen3-14B.Q4_K_M.gguf
      sha256: ee624d4be12433277bb9a340d3e5aabf5eb68fc788a7048ee99917edaa46494a
      uri: huggingface://MaziyarPanahi/Qwen3-14B-GGUF/Qwen3-14B.Q4_K_M.gguf
- !!merge <<: *qwen3
  name: "qwen3-8b"
  urls:
    - https://huggingface.co/Qwen/Qwen3-8B
    - https://huggingface.co/MaziyarPanahi/Qwen3-8B-GGUF
  description: |
    Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Built upon extensive training, Qwen3 delivers groundbreaking advancements in reasoning, instruction-following, agent capabilities, and multilingual support, with the following key features:

        Uniquely support of seamless switching between thinking mode (for complex logical reasoning, math, and coding) and non-thinking mode (for efficient, general-purpose dialogue) within single model, ensuring optimal performance across various scenarios.
        Significantly enhancement in its reasoning capabilities, surpassing previous QwQ (in thinking mode) and Qwen2.5 instruct models (in non-thinking mode) on mathematics, code generation, and commonsense logical reasoning.
        Superior human preference alignment, excelling in creative writing, role-playing, multi-turn dialogues, and instruction following, to deliver a more natural, engaging, and immersive conversational experience.
        Expertise in agent capabilities, enabling precise integration with external tools in both thinking and unthinking modes and achieving leading performance among open-source models in complex agent-based tasks.
        Support of 100+ languages and dialects with strong capabilities for multilingual instruction following and translation.

    Model Overview

    Qwen3-8B has the following features:

        Type: Causal Language Models
        Training Stage: Pretraining & Post-training
        Number of Parameters: 8.2B
        Number of Paramaters (Non-Embedding): 6.95B
        Number of Layers: 36
        Number of Attention Heads (GQA): 32 for Q and 8 for KV
        Context Length: 32,768 natively and 131,072 tokens with YaRN.
  overrides:
    parameters:
      model: Qwen3-8B.Q4_K_M.gguf
  files:
    - filename: Qwen3-8B.Q4_K_M.gguf
      sha256: 376902d50612ecfc5bd8b268f376c04d10ad7e480f99a1483b833f04344a549e
      uri: huggingface://MaziyarPanahi/Qwen3-8B-GGUF/Qwen3-8B.Q4_K_M.gguf
- !!merge <<: *qwen3
  name: "qwen3-4b"
  urls:
    - https://huggingface.co/Qwen/Qwen3-4B
    - https://huggingface.co/MaziyarPanahi/Qwen3-4B-GGUF
  description: |
    Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Built upon extensive training, Qwen3 delivers groundbreaking advancements in reasoning, instruction-following, agent capabilities, and multilingual support, with the following key features:

        Uniquely support of seamless switching between thinking mode (for complex logical reasoning, math, and coding) and non-thinking mode (for efficient, general-purpose dialogue) within single model, ensuring optimal performance across various scenarios.
        Significantly enhancement in its reasoning capabilities, surpassing previous QwQ (in thinking mode) and Qwen2.5 instruct models (in non-thinking mode) on mathematics, code generation, and commonsense logical reasoning.
        Superior human preference alignment, excelling in creative writing, role-playing, multi-turn dialogues, and instruction following, to deliver a more natural, engaging, and immersive conversational experience.
        Expertise in agent capabilities, enabling precise integration with external tools in both thinking and unthinking modes and achieving leading performance among open-source models in complex agent-based tasks.
        Support of 100+ languages and dialects with strong capabilities for multilingual instruction following and translation.

    Qwen3-4B has the following features:

        Type: Causal Language Models
        Training Stage: Pretraining & Post-training
        Number of Parameters: 4.0B
        Number of Paramaters (Non-Embedding): 3.6B
        Number of Layers: 36
        Number of Attention Heads (GQA): 32 for Q and 8 for KV
        Context Length: 32,768 natively and 131,072 tokens with YaRN.
  overrides:
    parameters:
      model: Qwen3-4B.Q4_K_M.gguf
  files:
    - filename: Qwen3-4B.Q4_K_M.gguf
      sha256: a37931937683a723ae737a0c6fc67dab7782fd8a1b9dea2ca445b7a1dbd5ca3a
      uri: huggingface://MaziyarPanahi/Qwen3-4B-GGUF/Qwen3-4B.Q4_K_M.gguf
- !!merge <<: *qwen3
  name: "qwen3-1.7b"
  urls:
    - https://huggingface.co/Qwen/Qwen3-1.7B
    - https://huggingface.co/MaziyarPanahi/Qwen3-1.7B-GGUF
  description: |
    Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Built upon extensive training, Qwen3 delivers groundbreaking advancements in reasoning, instruction-following, agent capabilities, and multilingual support, with the following key features:

        Uniquely support of seamless switching between thinking mode (for complex logical reasoning, math, and coding) and non-thinking mode (for efficient, general-purpose dialogue) within single model, ensuring optimal performance across various scenarios.
        Significantly enhancement in its reasoning capabilities, surpassing previous QwQ (in thinking mode) and Qwen2.5 instruct models (in non-thinking mode) on mathematics, code generation, and commonsense logical reasoning.
        Superior human preference alignment, excelling in creative writing, role-playing, multi-turn dialogues, and instruction following, to deliver a more natural, engaging, and immersive conversational experience.
        Expertise in agent capabilities, enabling precise integration with external tools in both thinking and unthinking modes and achieving leading performance among open-source models in complex agent-based tasks.
        Support of 100+ languages and dialects with strong capabilities for multilingual instruction following and translation.

    Qwen3-1.7B has the following features:

        Type: Causal Language Models
        Training Stage: Pretraining & Post-training
        Number of Parameters: 1.7B
        Number of Paramaters (Non-Embedding): 1.4B
        Number of Layers: 28
        Number of Attention Heads (GQA): 16 for Q and 8 for KV
        Context Length: 32,768
  overrides:
    parameters:
      model: Qwen3-1.7B.Q4_K_M.gguf
  files:
    - filename: Qwen3-1.7B.Q4_K_M.gguf
      sha256: ea2aa5f1cce3c8df81ae5fd292a6ed265b8393cc89534dc21fc5327cc974116a
      uri: huggingface://MaziyarPanahi/Qwen3-1.7B-GGUF/Qwen3-1.7B.Q4_K_M.gguf
- !!merge <<: *qwen3
  name: "qwen3-0.6b"
  urls:
    - https://huggingface.co/Qwen/Qwen3-0.6B
    - https://huggingface.co/MaziyarPanahi/Qwen3-0.6B-GGUF
  description: |
    Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Built upon extensive training, Qwen3 delivers groundbreaking advancements in reasoning, instruction-following, agent capabilities, and multilingual support, with the following key features:

        Uniquely support of seamless switching between thinking mode (for complex logical reasoning, math, and coding) and non-thinking mode (for efficient, general-purpose dialogue) within single model, ensuring optimal performance across various scenarios.
        Significantly enhancement in its reasoning capabilities, surpassing previous QwQ (in thinking mode) and Qwen2.5 instruct models (in non-thinking mode) on mathematics, code generation, and commonsense logical reasoning.
        Superior human preference alignment, excelling in creative writing, role-playing, multi-turn dialogues, and instruction following, to deliver a more natural, engaging, and immersive conversational experience.
        Expertise in agent capabilities, enabling precise integration with external tools in both thinking and unthinking modes and achieving leading performance among open-source models in complex agent-based tasks.
        Support of 100+ languages and dialects with strong capabilities for multilingual instruction following and translation.

    Qwen3-0.6B has the following features:

        Type: Causal Language Models
        Training Stage: Pretraining & Post-training
        Number of Parameters: 0.6B
        Number of Paramaters (Non-Embedding): 0.44B
        Number of Layers: 28
        Number of Attention Heads (GQA): 16 for Q and 8 for KV
        Context Length: 32,768
  overrides:
    parameters:
      model: Qwen3-0.6B.Q4_K_M.gguf
  files:
    - filename: Qwen3-0.6B.Q4_K_M.gguf
      sha256: d724c7e98bf2b04dbd76e79311e1070dbb55cf62b2e4d21abd2f85fed0f50c7e
      uri: https://www.modelscope.cn/models/unsloth/Qwen3-0.6B-GGUF/resolve/master/Qwen3-0.6B-Q5_K_M.gguf
- !!merge <<: *qwen3
  name: "mlabonne_qwen3-14b-abliterated"
  urls:
    - https://huggingface.co/mlabonne/Qwen3-14B-abliterated
    - https://huggingface.co/bartowski/mlabonne_Qwen3-14B-abliterated-GGUF
  description: |
    Qwen3-14B-abliterated is a 14B parameter model that is abliterated.
  overrides:
    parameters:
      model: mlabonne_Qwen3-14B-abliterated-Q4_K_M.gguf
  files:
    - filename: mlabonne_Qwen3-14B-abliterated-Q4_K_M.gguf
      uri: huggingface://bartowski/mlabonne_Qwen3-14B-abliterated-GGUF/mlabonne_Qwen3-14B-abliterated-Q4_K_M.gguf
      sha256: 3fe972a7c6e847ec791453b89a7333d369fbde329cbd4cc9a4f0598854db5d54
- !!merge <<: *qwen3
  name: "mlabonne_qwen3-8b-abliterated"
  urls:
    - https://huggingface.co/mlabonne/Qwen3-8B-abliterated
    - https://huggingface.co/bartowski/mlabonne_Qwen3-8B-abliterated-GGUF
  description: |
    Qwen3-8B-abliterated is a 8B parameter model that is abliterated.
  overrides:
    parameters:
      model: mlabonne_Qwen3-8B-abliterated-Q4_K_M.gguf
  files:
    - filename: mlabonne_Qwen3-8B-abliterated-Q4_K_M.gguf
      uri: huggingface://bartowski/mlabonne_Qwen3-8B-abliterated-GGUF/mlabonne_Qwen3-8B-abliterated-Q4_K_M.gguf
      sha256: 361557e69ad101ee22b1baf427283b7ddcf81bc7532b8cee8ac2c6b4d1b81ead
- !!merge <<: *qwen3
  name: "mlabonne_qwen3-4b-abliterated"
  urls:
    - https://huggingface.co/mlabonne/Qwen3-4B-abliterated
    - https://huggingface.co/bartowski/mlabonne_Qwen3-4B-abliterated-GGUF
  description: |
    Qwen3-4B-abliterated is a 4B parameter model that is abliterated.
  overrides:
    parameters:
      model: mlabonne_Qwen3-4B-abliterated-Q4_K_M.gguf
  files:
    - filename: mlabonne_Qwen3-4B-abliterated-Q4_K_M.gguf
      sha256: 004f7b8f59ccd5fa42258c52aa2087b89524cced84e955b9c8b115035ca073b2
      uri: huggingface://bartowski/mlabonne_Qwen3-4B-abliterated-GGUF/mlabonne_Qwen3-4B-abliterated-Q4_K_M.gguf
- !!merge <<: *qwen3
  name: "qwen3-30b-a3b-abliterated"
  urls:
    - https://huggingface.co/mlabonne/Qwen3-30B-A3B-abliterated
    - https://huggingface.co/mradermacher/Qwen3-30B-A3B-abliterated-GGUF
  description: |
    Abliterated version of Qwen3-30B-A3B by mlabonne.
  overrides:
    parameters:
      model: Qwen3-30B-A3B-abliterated.Q4_K_M.gguf
  files:
    - filename: Qwen3-30B-A3B-abliterated.Q4_K_M.gguf
      sha256: 60549f0232ed856dd0268e006e8f764620ea3eeaac3239ff0843e647dd9ae128
      uri: huggingface://mradermacher/Qwen3-30B-A3B-abliterated-GGUF/Qwen3-30B-A3B-abliterated.Q4_K_M.gguf
- !!merge <<: *qwen3
  name: "qwen3-8b-jailbroken"
  urls:
    - https://huggingface.co/cooperleong00/Qwen3-8B-Jailbroken
    - https://huggingface.co/mradermacher/Qwen3-8B-Jailbroken-GGUF
  description: |
    This jailbroken LLM is released strictly for academic research purposes in AI safety and model alignment studies. The author bears no responsibility for any misuse or harm resulting from the deployment of this model. Users must comply with all applicable laws and ethical guidelines when conducting research.
    A jailbroken Qwen3-8B model using weight orthogonalization[1].
    Implementation script: https://gist.github.com/cooperleong00/14d9304ba0a4b8dba91b60a873752d25
    [1]: Arditi, Andy, et al. "Refusal in language models is mediated by a single direction." arXiv preprint arXiv:2406.11717 (2024).
  overrides:
    parameters:
      model: Qwen3-8B-Jailbroken.Q4_K_M.gguf
  files:
    - filename: Qwen3-8B-Jailbroken.Q4_K_M.gguf
      sha256: 14ded84a1791a95285829abcc76ed9ca4fa61c469e0e94b53a4224ce46e34b41
      uri: huggingface://mradermacher/Qwen3-8B-Jailbroken-GGUF/Qwen3-8B-Jailbroken.Q4_K_M.gguf
- !!merge <<: *qwen3
  name: "fast-math-qwen3-14b"
  urls:
    - https://huggingface.co/RabotniKuma/Fast-Math-Qwen3-14B
    - https://huggingface.co/mradermacher/Fast-Math-Qwen3-14B-GGUF
  description: |
    By applying SFT and GRPO on difficult math problems, we enhanced the performance of DeepSeek-R1-Distill-Qwen-14B and developed Fast-Math-R1-14B, which achieves approx. 30% faster inference on average, while maintaining accuracy.

    In addition, we trained and open-sourced Fast-Math-Qwen3-14B, an efficiency-optimized version of Qwen3-14B`, following the same approach.

    Compared to Qwen3-14B, this model enables approx. 65% faster inference on average, with minimal loss in performance.

    Technical details can be found in our github repository.

    Note: This model likely inherits the ability to perform inference in TIR mode from the original model. However, all of our experiments were conducted in CoT mode, and its performance in TIR mode has not been evaluated.
  overrides:
    parameters:
      model: Fast-Math-Qwen3-14B.Q4_K_M.gguf
  files:
    - filename: Fast-Math-Qwen3-14B.Q4_K_M.gguf
      sha256: 8711208a9baa502fc5e943446eb5efe62eceafb6778920af5415235a3dba4d64
      uri: huggingface://mradermacher/Fast-Math-Qwen3-14B-GGUF/Fast-Math-Qwen3-14B.Q4_K_M.gguf
- !!merge <<: *qwen3
  name: "josiefied-qwen3-8b-abliterated-v1"
  urls:
    - https://huggingface.co/Goekdeniz-Guelmez/Josiefied-Qwen3-8B-abliterated-v1
    - https://huggingface.co/mradermacher/Josiefied-Qwen3-8B-abliterated-v1-GGUF
  description: |
    The JOSIEFIED model family represents a series of highly advanced language models built upon renowned architectures such as Alibaba’s Qwen2/2.5/3, Google’s Gemma3, and Meta’s LLaMA3/4. Covering sizes from 0.5B to 32B parameters, these models have been significantly modified (“abliterated”) and further fine-tuned to maximize uncensored behavior without compromising tool usage or instruction-following abilities.
    Despite their rebellious spirit, the JOSIEFIED models often outperform their base counterparts on standard benchmarks — delivering both raw power and utility.
    These models are intended for advanced users who require unrestricted, high-performance language generation.
    Introducing Josiefied-Qwen3-8B-abliterated-v1, a new addition to the JOSIEFIED family — fine-tuned with a focus on openness and instruction alignment.
  overrides:
    parameters:
      model: Josiefied-Qwen3-8B-abliterated-v1.Q4_K_M.gguf
  files:
    - filename: Josiefied-Qwen3-8B-abliterated-v1.Q4_K_M.gguf
      sha256: 1de498fe269116d448a52cba3796bbad0a2ac4dc1619ff6b46674ba344dcf69d
      uri: huggingface://mradermacher/Josiefied-Qwen3-8B-abliterated-v1-GGUF/Josiefied-Qwen3-8B-abliterated-v1.Q4_K_M.gguf
- !!merge <<: *qwen3
  name: "furina-8b"
  urls:
    - https://huggingface.co/minchyeom/Furina-8B
    - https://huggingface.co/mradermacher/Furina-8B-GGUF
  description: |
    A model that is fine-tuned to be Furina, the Hydro Archon and Judge of Fontaine from Genshin Impact.
  overrides:
    parameters:
      model: Furina-8B.Q4_K_M.gguf
  files:
    - filename: Furina-8B.Q4_K_M.gguf
      sha256: 8f0e825eca83b54eeff60b1b46c8b504de1777fe2ff10f83f12517982ae93cb3
      uri: huggingface://mradermacher/Furina-8B-GGUF/Furina-8B.Q4_K_M.gguf
- !!merge <<: *qwen3
  name: "shuttleai_shuttle-3.5"
  icon: https://storage.shuttleai.com/shuttle-3.5.png
  urls:
    - https://huggingface.co/shuttleai/shuttle-3.5
    - https://huggingface.co/bartowski/shuttleai_shuttle-3.5-GGUF
  description: |
    A fine-tuned version of Qwen3 32b, emulating the writing style of Claude 3 models and thoroughly trained on role-playing data.

        Uniquely support of seamless switching between thinking mode (for complex logical reasoning, math, and coding) and non-thinking mode (for efficient, general-purpose dialogue) within single model, ensuring optimal performance across various scenarios.
        Significantly enhancement in its reasoning capabilities, surpassing previous QwQ (in thinking mode) and Qwen2.5 instruct models (in non-thinking mode) on mathematics, code generation, and commonsense logical reasoning.
        Superior human preference alignment, excelling in creative writing, role-playing, multi-turn dialogues, and instruction following, to deliver a more natural, engaging, and immersive conversational experience.
        Expertise in agent capabilities, enabling precise integration with external tools in both thinking and unthinking modes and achieving leading performance among open-source models in complex agent-based tasks.
        Support of 100+ languages and dialects with strong capabilities for multilingual instruction following and translation.
    Shuttle 3.5 has the following features:

        Type: Causal Language Models
        Training Stage: Pretraining & Post-training
        Number of Parameters: 32.8B
        Number of Paramaters (Non-Embedding): 31.2B
        Number of Layers: 64
        Number of Attention Heads (GQA): 64 for Q and 8 for KV
        Context Length: 32,768 natively and 131,072 tokens with YaRN.
  overrides:
    parameters:
      model: shuttleai_shuttle-3.5-Q4_K_M.gguf
  files:
    - filename: shuttleai_shuttle-3.5-Q4_K_M.gguf
      sha256: c5defd3b45aa5f9bf56ce379b6346f99684bfddfe332329e91cfab2853015374
      uri: huggingface://bartowski/shuttleai_shuttle-3.5-GGUF/shuttleai_shuttle-3.5-Q4_K_M.gguf
- !!merge <<: *qwen3
  name: "amoral-qwen3-14b"
  icon: https://cdn-uploads.huggingface.co/production/uploads/62f93f9477b722f1866398c2/Jvn4zX2BvTIBuleqbkKq6.png
  urls:
    - https://huggingface.co/soob3123/amoral-qwen3-14B
    - https://huggingface.co/mradermacher/amoral-qwen3-14B-GGUF
  description: |
    Core Function:

    Produces analytically neutral responses to sensitive queries
    Maintains factual integrity on controversial subjects
    Avoids value-judgment phrasing patterns

    No inherent moral framing ("evil slop" reduction)
    Emotionally neutral tone enforcement
    Epistemic humility protocols (avoids "thrilling", "wonderful", etc.)
  overrides:
    parameters:
      model: amoral-qwen3-14B.Q4_K_M.gguf
  files:
    - filename: amoral-qwen3-14B.Q4_K_M.gguf
      sha256: 7a73332b4dd49d5df1de2dbe84fc274019f33e564bcdce722e6e2ddf4e93cc77
      uri: huggingface://mradermacher/amoral-qwen3-14B-GGUF/amoral-qwen3-14B.Q4_K_M.gguf
- !!merge <<: *qwen3
  name: "qwen-3-32b-medical-reasoning-i1"
  urls:
    - https://huggingface.co/nicoboss/Qwen-3-32B-Medical-Reasoning
    - https://huggingface.co/mradermacher/Qwen-3-32B-Medical-Reasoning-i1-GGUF
  description: |
    This is https://huggingface.co/kingabzpro/Qwen-3-32B-Medical-Reasoning applied to https://huggingface.co/Qwen/Qwen3-32B Original model card created by @kingabzpro
    Original model card from @kingabzpro
    Fine-tuning Qwen3-32B in 4-bit Quantization for Medical Reasoning

    This project fine-tunes the Qwen/Qwen3-32B model using a medical reasoning dataset (FreedomIntelligence/medical-o1-reasoning-SFT) with 4-bit quantization for memory-efficient training.
  overrides:
    parameters:
      model: Qwen-3-32B-Medical-Reasoning.i1-Q4_K_M.gguf
  files:
    - filename: Qwen-3-32B-Medical-Reasoning.i1-Q4_K_M.gguf
      sha256: 3d5ca0c8dfde8f9466e4d89839f08cd2f45ef97d6c28fa61f9428645877497b0
      uri: huggingface://mradermacher/Qwen-3-32B-Medical-Reasoning-i1-GGUF/Qwen-3-32B-Medical-Reasoning.i1-Q4_K_M.gguf
- !!merge <<: *qwen3
  name: "smoothie-qwen3-8b"
  icon: https://github.com/dnotitia/smoothie-qwen/raw/main/asset/smoothie-qwen-logo.png
  urls:
    - https://huggingface.co/dnotitia/Smoothie-Qwen3-8B
    - https://huggingface.co/mradermacher/Smoothie-Qwen3-8B-GGUF
  description: |
    Smoothie Qwen is a lightweight adjustment tool that smooths token probabilities in Qwen and similar models, enhancing balanced multilingual generation capabilities. For more details, please refer to https://github.com/dnotitia/smoothie-qwen.
  overrides:
    parameters:
      model: Smoothie-Qwen3-8B.Q4_K_M.gguf
  files:
    - filename: Smoothie-Qwen3-8B.Q4_K_M.gguf
      sha256: 36fc6df285c35beb8f1fdb46b3854bc4f420d3600afa397bf6a89e2ce5480112
      uri: huggingface://mradermacher/Smoothie-Qwen3-8B-GGUF/Smoothie-Qwen3-8B.Q4_K_M.gguf
- !!merge <<: *qwen3
  name: "qwen3-30b-a1.5b-high-speed"
  icon: https://huggingface.co/DavidAU/Qwen3-30B-A1.5B-High-Speed/resolve/main/star-wars-hans-solo.gif
  urls:
    - https://huggingface.co/DavidAU/Qwen3-30B-A1.5B-High-Speed
    - https://huggingface.co/mradermacher/Qwen3-30B-A1.5B-High-Speed-GGUF
  description: |
    This repo contains the full precision source code, in "safe tensors" format to generate GGUFs, GPTQ, EXL2, AWQ, HQQ and other formats. The source code can also be used directly.

    This is a simple "finetune" of the Qwen's "Qwen 30B-A3B" (MOE) model, setting the experts in use from 8 to 4 (out of 128 experts).

    This method close to doubles the speed of the model and uses 1.5B (of 30B) parameters instead of 3B (of 30B) parameters. Depending on the application you may want to use the regular model ("30B-A3B"), and use this model for simpler use case(s) although I did not notice any loss of function during routine (but not extensive) testing.

    Example generation (Q4KS, CPU) at the bottom of this page using 4 experts / this model.

    More complex use cases may benefit from using the normal version.

    For reference:

        Cpu only operation Q4KS (windows 11) jumps from 12 t/s to 23 t/s.
        GPU performance IQ3S jumps from 75 t/s to over 125 t/s. (low to mid level card)

    Context size: 32K + 8K for output (40k total)
  overrides:
    parameters:
      model: Qwen3-30B-A1.5B-High-Speed.Q4_K_M.gguf
  files:
    - filename: Qwen3-30B-A1.5B-High-Speed.Q4_K_M.gguf
      sha256: 2fca25524abe237483de64599bab54eba8fb22088fc21e30ba45ea8fb04dd1e0
      uri: huggingface://mradermacher/Qwen3-30B-A1.5B-High-Speed-GGUF/Qwen3-30B-A1.5B-High-Speed.Q4_K_M.gguf
- !!merge <<: *qwen3
  name: "kalomaze_qwen3-16b-a3b"
  urls:
    - https://huggingface.co/kalomaze/Qwen3-16B-A3B
    - https://huggingface.co/bartowski/kalomaze_Qwen3-16B-A3B-GGUF
  description: |
    A man-made horror beyond your comprehension.

    But no, seriously, this is my experiment to:

        measure the probability that any given expert will activate (over my personal set of fairly diverse calibration data), per layer
        prune 64/128 of the least used experts per layer (with reordered router and indexing per layer)

    It can still write semi-coherently without any additional training or distillation done on top of it from the original 30b MoE. The .txt files with the original measurements are provided in the repo along with the exported weights.

    Custom testing to measure the experts was done on a hacked version of vllm, and then I made a bespoke script to selectively export the weights according to the measurements.
  overrides:
    parameters:
      model: kalomaze_Qwen3-16B-A3B-Q4_K_M.gguf
  files:
    - filename: kalomaze_Qwen3-16B-A3B-Q4_K_M.gguf
      sha256: 34c86e1a956349632a05af37a104203823859363f141e1002abe6017349fbdcb
      uri: huggingface://bartowski/kalomaze_Qwen3-16B-A3B-GGUF/kalomaze_Qwen3-16B-A3B-Q4_K_M.gguf

